{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe36774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Charger les données\n",
    "airports = pd.read_csv('../data/airports.csv')\n",
    "flights = pd.read_csv('../data/flights.csv')\n",
    "planes = pd.read_csv('../data/planes.csv')\n",
    "weather = pd.read_csv('../data/weather.csv')\n",
    "with open('../data/airlines.json', 'r') as f:\n",
    "    airlines = pd.json_normalize(json.load(f))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b2f8aa",
   "metadata": {},
   "source": [
    "### Nettoyage table Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "723a4782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows in flights: 252704\n",
      "Number of rows after removing null primary keys: 252704\n",
      "Number of rows after removing duplicates: 252704\n"
     ]
    }
   ],
   "source": [
    "# Nombre initial de lignes\n",
    "initial_rows = len(flights)\n",
    "print(f\"Initial number of rows in flights: {initial_rows}\")\n",
    "\n",
    "# Supprimer les lignes où les clés primaires sont nulles\n",
    "flights_cleaned = flights.dropna(subset=['year', 'month', 'day', 'flight', 'origin', 'dest', 'tailnum', 'carrier'])\n",
    "cleaned_rows = len(flights_cleaned)\n",
    "print(f\"Number of rows after removing null primary keys: {cleaned_rows}\")\n",
    "\n",
    "# Supprimer les doublons basés sur les clés primaires\n",
    "flights_cleaned = flights_cleaned.drop_duplicates(subset=['year', 'month', 'day', 'flight', 'origin', 'dest', 'tailnum', 'carrier'])\n",
    "deduplicated_rows = len(flights_cleaned)\n",
    "print(f\"Number of rows after removing duplicates: {deduplicated_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810190b",
   "metadata": {},
   "source": [
    "### Nettoyage table Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dfe7a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans 'faa'\n",
    "airports_cleaned = airports.dropna(subset=['faa'])\n",
    "\n",
    "# Supprimer les doublons basés sur 'faa'\n",
    "airports_cleaned = airports_cleaned.drop_duplicates(subset=['faa'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0689d4",
   "metadata": {},
   "source": [
    "### Nettoyage table Planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be05d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans 'tailnum'\n",
    "planes_cleaned = planes.dropna(subset=['tailnum'])\n",
    "\n",
    "# Supprimer les doublons basés sur 'tailnum'\n",
    "planes_cleaned = planes_cleaned.drop_duplicates(subset=['tailnum'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb8e3c4",
   "metadata": {},
   "source": [
    "### Nettoyage table Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4606a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec des valeurs manquantes dans 'origin'\n",
    "weather_cleaned = weather.dropna(subset=['origin'])\n",
    "\n",
    "# Supprimer les doublons basés sur les clés primaires de la table weather\n",
    "weather_cleaned = weather_cleaned.drop_duplicates(subset=['origin', 'year', 'month', 'day', 'hour'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943db2e",
   "metadata": {},
   "source": [
    "### Vérification et Ajout des Clés Artificielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34f03827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing planes: 717\n",
      "Number of missing origin airports: 0\n",
      "Number of missing destination airports: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZaawKZPC\\AppData\\Local\\Temp\\ipykernel_12252\\948515361.py:13: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  airports_cleaned = pd.concat([airports_cleaned, new_airports]).drop_duplicates(subset=['faa']).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Flights - Planes\n",
    "missing_planes = flights_cleaned[~flights_cleaned['tailnum'].isin(planes_cleaned['tailnum'])]['tailnum'].drop_duplicates()\n",
    "print(f\"Number of missing planes: {len(missing_planes)}\")\n",
    "\n",
    "# Flights - Airports\n",
    "missing_airports_origin = flights_cleaned[~flights_cleaned['origin'].isin(airports_cleaned['faa'])]['origin'].drop_duplicates()\n",
    "missing_airports_dest = flights_cleaned[~flights_cleaned['dest'].isin(airports_cleaned['faa'])]['dest'].drop_duplicates()\n",
    "print(f\"Number of missing origin airports: {len(missing_airports_origin)}\")\n",
    "print(f\"Number of missing destination airports: {len(missing_airports_dest)}\")\n",
    "\n",
    "# Ajouter les aéroports manquants à la table airports\n",
    "new_airports = pd.DataFrame({'faa': pd.concat([missing_airports_origin, missing_airports_dest]), 'name': None, 'lat': None, 'lon': None, 'alt': None, 'tz': None, 'dst': None, 'tzone': None})\n",
    "airports_cleaned = pd.concat([airports_cleaned, new_airports]).drop_duplicates(subset=['faa']).reset_index(drop=True)\n",
    "\n",
    "# Ajouter des clés artificielles à flights\n",
    "flights_cleaned['id'] = range(1, len(flights_cleaned) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0670d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning complete and files saved.\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les données nettoyées\n",
    "flights_cleaned.to_csv('../data/clean/cleaned_flights.csv', index=False)\n",
    "airports_cleaned.to_csv('../data/clean/cleaned_airports.csv', index=False)\n",
    "planes_cleaned.to_csv('../data/clean/cleaned_planes.csv', index=False)\n",
    "weather_cleaned.to_csv('../data/clean/cleaned_weather.csv', index=False)\n",
    "with open('..data/cleaned_airlines.json', 'w') as f:\n",
    "    json.dump(airlines.to_dict(orient='records'), f, indent=4)\n",
    "\n",
    "print(\"Data cleaning complete and files saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
